{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think Python \n",
    "\n",
    "## Chapter 14 - Files\n",
    "\n",
    "*HTML of this chapter in \"Think Python 2e\" can be found [here](http://greenteapress.com/thinkpython2/html/thinkpython2015.html \"Chapter 14\").*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.12  Exercises\n",
    "\n",
    "#### Exercise 1  \n",
    "\n",
    "*Write a function called `sed` that takes as arguments a pattern string, a replacement string, and two filenames; it should read the first file and write the contents into the second file (creating it if necessary). If the pattern string appears anywhere in the file, it should be replaced with the replacement string.*\n",
    "\n",
    "*If an error occurs while opening, reading, writing or closing files, your program should catch the exception, print an error message, and exit.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def sed(filename1, filename2, pattern, replacement):\n",
    "    \n",
    "    try:\n",
    "        fin = open(filename1, 'r')\n",
    "        fout = open(filename2, 'w')\n",
    "\n",
    "        for line in fin:\n",
    "            fout.write(line.replace(pattern, replacement))\n",
    "\n",
    "        fout.close()\n",
    "        \n",
    "    except:\n",
    "        print(\"That didn't go as planned...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Text of `'test1.txt'`:__*\n",
    "\n",
    "> *Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Sed libero enim sed faucibus turpis in eu. Viverra ipsum nunc aliquet bibendum enim facilisis gravida neque convallis. Lectus sit amet est placerat in egestas erat imperdiet sed. Varius morbi enim nunc faucibus a pellentesque sit. Imperdiet sed euismod nisi porta. Phasellus vestibulum lorem sed risus ultricies tristique nulla aliquet enim. At risus viverra adipiscing at in tellus integer feugiat. Pellentesque dignissim enim sit amet. Fringilla phasellus faucibus scelerisque eleifend donec pretium vulputate. Consectetur adipiscing elit duis tristique sollicitudin nibh sit. Tincidunt lobortis feugiat vivamus at augue eget. Cursus vitae congue mauris rhoncus aenean vel.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed('test1.txt', 'test2.txt', 'et', 'zzzzz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Text of `'test1.txt'` after running `sed`:__*\n",
    "\n",
    ">*Lorem ipsum dolor sit amzzzzz, consectzzzzzur adipiscing elit, sed do eiusmod tempor incididunt ut labore zzzzz dolore magna aliqua. Sed libero enim sed faucibus turpis in eu. Viverra ipsum nunc aliquzzzzz bibendum enim facilisis gravida neque convallis. Lectus sit amzzzzz est placerat in egestas erat imperdizzzzz sed. Varius morbi enim nunc faucibus a pellentesque sit. Imperdizzzzz sed euismod nisi porta. Phasellus vestibulum lorem sed risus ultricies tristique nulla aliquzzzzz enim. At risus viverra adipiscing at in tellus integer feugiat. Pellentesque dignissim enim sit amzzzzz. Fringilla phasellus faucibus scelerisque eleifend donec przzzzzium vulputate. Consectzzzzzur adipiscing elit duis tristique sollicitudin nibh sit. Tincidunt lobortis feugiat vivamus at augue egzzzzz. Cursus vitae congue mauris rhoncus aenean vel.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That didn't go as planned...\n"
     ]
    }
   ],
   "source": [
    "# 'test3.txt' does not exist\n",
    "\n",
    "sed('test3.txt', 'test2.txt', 'et', 'rocking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2  \n",
    "\n",
    "*Write a module that imports `anagram_sets` and provides two new functions: `store_anagrams` should store the anagram dictionary in a “shelf”; `read_anagrams` should look up a word and return a list of its anagrams.* \n",
    "\n",
    "*__I'm using jupyter notebooks, so this will be a little different compared to someone running Python from the console:__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load anagram_sets.py \n",
    "def sort_letters(string):\n",
    "    \"\"\"\n",
    "    Returns the letters in string as a new string\n",
    "    whose letters are in alphabetical order.\n",
    "    \"\"\"\n",
    "        \n",
    "    return ''.join(sorted(list(string.lower())))\n",
    "\n",
    "def find_anagrams(text):\n",
    "    \"\"\"\n",
    "    Takes a text and returns a list of tuples of anagrams.\n",
    "    First item in the tuple is the number of anagrams formed.\n",
    "    Second item is the letters used.\n",
    "    Third item is the anagrams.\n",
    "    \"\"\"\n",
    "\n",
    "    sorted_dict = {}\n",
    "\n",
    "    for line in text:\n",
    "        orig_word = line.strip()\n",
    "        sorted_word = sort_letters(orig_word)\n",
    "        sorted_dict.setdefault(sorted_word, []).append(orig_word)\n",
    "            \n",
    "    return sorted_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run anagram_sets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_words = \"E:\\\\words.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__`.write()` won't work with dictionaries, and `pickle` is very slow, meaning we should use `shelve`, which was only mentioned - and not covered - in \"Think Python 2e\":__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "\n",
    "def store_anagrams(path, dict_name):\n",
    "    \"\"\"\n",
    "    Creates a dictionary of anagrams and stores\n",
    "    it.\n",
    "    \n",
    "    Arguments:\n",
    "    path: Path where word list can be found.\n",
    "    dict_name: Name to be given to the \n",
    "        resulting dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    anagrams = find_anagrams(open(path))\n",
    "\n",
    "    ad = shelve.open(dict_name)\n",
    "    for k, v in anagrams.items():\n",
    "        ad[k] = v\n",
    "    ad.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `path_to_words` should be the local path to `words.txt`\n",
    "\n",
    "store_anagrams(path_to_words, 'anagram_dict.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_anagrams(word, d):\n",
    "    \"\"\"\n",
    "    Retrieves the anagrams for a word from an\n",
    "    existing anagrams dictionary.\n",
    "    \n",
    "    Arguments:\n",
    "    word: The word to be queried.\n",
    "    d: The anagrams dictionary.  Must be in the \n",
    "        working directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        sorted_word = sort_letters(word)\n",
    "        s = shelve.open(d)\n",
    "        anagram = s[sorted_word]\n",
    "        s.close()\n",
    "\n",
    "        print(anagram)\n",
    "    except:\n",
    "        print(\"'{}' was not found in '{}'.\".format(word, d))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opts', 'post', 'pots', 'spot', 'stop', 'tops']\n"
     ]
    }
   ],
   "source": [
    "read_anagrams('post', 'anagram_dict.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['least', 'setal', 'slate', 'stale', 'steal', 'stela', 'taels', 'tales', 'teals', 'tesla']\n"
     ]
    }
   ],
   "source": [
    "read_anagrams('least', 'anagram_dict.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ohisashiburi' was not found in 'anagram_dict.db'.\n"
     ]
    }
   ],
   "source": [
    "read_anagrams('ohisashiburi', 'anagram_dict.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3  \n",
    "\n",
    "*In a large collection of MP3 files, there may be more than one copy of the same song, stored in different directories or with different file names. The goal of this exercise is to search for duplicates.*\n",
    "\n",
    "<ol>\n",
    "    <li><i>Write a program that searches a directory and all of its subdirectories, recursively, and returns a list of complete paths for all files with a given suffix (like .mp3). Hint: os.path provides several useful functions for manipulating file and path names.</li></i>\n",
    "    <li><i>To recognize duplicates, you can use md5sum to compute a “checksum” for each files. If two files have the same checksum, they probably have the same contents.</li></i>\n",
    "    <li><i>To double-check, you can use the Unix command diff.</li></i>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__I had a number of difficulties with this problem, and for the wrong reasons:  The first problem I had was with `popen`, which wasn't working correctly on my system (perhaps because it was deprecrated).  Therefore, I wasn't able to use `md5sum` the way shown in the book. As a result, I ended up using the library `hashlib`, which wasn't so difficult to use.  Furthermore, since MD5 has vulnerabilities, I decided to use SHA256 instead, which worked just as well for my purposes.  Another difficulty I had was that I'm not using a UNIX system, so instead of using the UNIX command `diff`, I had to use `cmp` from the `filecmp` library, which - as far as I can tell - works just as well for a problem like this.__*\n",
    "\n",
    "*__In the end, I ended up looking at the author's solution for assistance on this problem, which I generally have not done while working my way through \"Think Python 2e\". It's clear to see that my code is influenced on the author's code, but further to the differences noted above, I made one more key addition: the author's code used the UNIX command `diff` to compare pairs of files, but it's possible that there may be more than two identical files in a directory.  My function `find_duplicates` can check multiple files for identical contents.__*\n",
    "\n",
    "*__One final note: this code is not particularly fast, and might lag with large folders.__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, hashlib, filecmp\n",
    "\n",
    "def make_sha256(path):\n",
    "    \"\"\"\n",
    "    Creates a SHA-256 hash object for the file at\n",
    "    designated path.\n",
    "    \"\"\"\n",
    "    return hashlib.sha256(open(path,'rb').read()).hexdigest()\n",
    "\n",
    "def walk(dirname):\n",
    "    \"\"\"\n",
    "    Nearly identical to the code presented in \n",
    "    the solutions for 'Think Python 2e', chapter 14\n",
    "    \"\"\"\n",
    "\n",
    "    names = []\n",
    "\n",
    "    for name in os.listdir(dirname):\n",
    "        path = os.path.join(dirname, name)\n",
    "        \n",
    "        if os.path.isfile(path):\n",
    "            names.append(path)\n",
    "        else:\n",
    "            names.extend(walk(path))\n",
    "            \n",
    "    return names\n",
    "\n",
    "def make_dict_for_suffix(dirname, suffix):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of checksums for all files \n",
    "    in dirname with designated suffix.\n",
    "    \"\"\"\n",
    "    \n",
    "    files = walk(dirname)\n",
    "    \n",
    "    d = {}\n",
    "    for file in files:\n",
    "        if file.endswith(suffix):\n",
    "            sha256 = make_sha256(file)\n",
    "            \n",
    "            if sha256 in d:\n",
    "                d[sha256].append(file)\n",
    "            else:\n",
    "                d[sha256] = [file]\n",
    "                \n",
    "    return d\n",
    "                \n",
    "def confirm_same(file1, file2):\n",
    "    \"\"\"\n",
    "    Returns True if two files have same contents.\n",
    "    \"\"\"\n",
    "    return filecmp.cmp(file1, file2)\n",
    "    \n",
    "def find_duplicates(d):\n",
    "    \"\"\"\n",
    "    Prints file paths of files in map d that have\n",
    "    same checksums.  Confirms if files have identical \n",
    "    contents. Can handle any number of identical files.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    for k, v in d.items():\n",
    "        if len(v) > 1:\n",
    "            print('The following files have identical checksums:\\n')\n",
    "            for f in v:\n",
    "                print('\\t{}\\n'.format(f))\n",
    "\n",
    "            for i in range(len(v)):\n",
    "                for j in range(i + 1, len(v)):\n",
    "                    if confirm_same(d[k][i], d[k][j]):\n",
    "                        print('\\nThe following two files have identical contents: \\n\\n \\t{} \\n\\n and \\n\\n \\t{} \\n'.format(d[k][i], d[k][j]))\n",
    "                    else:\n",
    "                        print('\\nThe following two files do NOT have identical contents: \\n\\n \\t{} \\n\\n and \\n\\n \\t{} \\n'.format(d[k][i], d[k][j]))\n",
    "                        \n",
    "                    j += 1\n",
    "                i += 1\n",
    "                \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\Chapter_14_Music\"\n",
    "\n",
    "d = make_dict_for_suffix(path, suffix = '.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files have identical checksums:\n",
      "\n",
      "\tE:\\Chapter_14_Music\\duplicate1\\02 Janglin.mp3\n",
      "\n",
      "\tE:\\Chapter_14_Music\\duplicate2\\02 Janglin.mp3\n",
      "\n",
      "\tE:\\Chapter_14_Music\\Edward Sharpe & The Magnetic Zeros\\Up From Below\\02 Janglin.mp3\n",
      "\n",
      "\n",
      "The following two files have identical contents: \n",
      "\n",
      " \tE:\\Chapter_14_Music\\duplicate1\\02 Janglin.mp3 \n",
      "\n",
      " and \n",
      "\n",
      " \tE:\\Chapter_14_Music\\duplicate2\\02 Janglin.mp3 \n",
      "\n",
      "\n",
      "The following two files have identical contents: \n",
      "\n",
      " \tE:\\Chapter_14_Music\\duplicate1\\02 Janglin.mp3 \n",
      "\n",
      " and \n",
      "\n",
      " \tE:\\Chapter_14_Music\\Edward Sharpe & The Magnetic Zeros\\Up From Below\\02 Janglin.mp3 \n",
      "\n",
      "\n",
      "The following two files have identical contents: \n",
      "\n",
      " \tE:\\Chapter_14_Music\\duplicate2\\02 Janglin.mp3 \n",
      "\n",
      " and \n",
      "\n",
      " \tE:\\Chapter_14_Music\\Edward Sharpe & The Magnetic Zeros\\Up From Below\\02 Janglin.mp3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_duplicates(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
